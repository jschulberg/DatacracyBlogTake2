---
title: Next Word Generation with Markov Chains
author: Justin S.
date: '2024-01-15'
slug: [Markov-Chain]
categories:
  - nlp
  - markov
tags:
  - Python
comments: yes
featured_image: ''
share: yes
draft: true
description: '<Insert description here>'
---

This article leverages some work I did for my grad program's Bayesian Statistics Course. Specifically, it uses Bayesian inference for the task of [*next word prediction*](https://arxiv.org/abs/2306.17184).

# Next Word Prediction
A common task that language models try to solve is next word prediction. Given a series of words in a sentence, can the language model predict the *next* word that should appear? Ideally, the model would use understanding of the prior words that appeared 



## Bayes' Formula
The traditional Bayes' formula, given events A and B, is:

$$
P(A|B) = \frac{P(B|A) * P(A)}{P(B)}
$$

Given a prior, $\theta$, which represents the probability distribution of a data object *before* it's observed, and a likelihood $y$, which represents the probability of falling under a specific category/class, we can generalize the above formula to compute the posterior as such:

$$
p(\theta|y) = \frac{p(y|\theta)*p(\theta)}{p(y)}
$$

where $p(\theta|y)$ represents the posterior probability: the probability after the evidence from our prior is considered.


## A Simple Application of Bayes for Next Word Prediction
Let's start simple. We'll take some text and tokenize it into words. I'll then create a matrix that shows the probability that a word appears given the word that comes directly before it. Again, this is a naive approach because I will *only* look at the word that comes immediately before. That makes the approach act more like a [Markovian transition matrix](https://www.jstor.org/stable/2584334), since it's just looking at the state immediately before to make a prediction, rather than all the events that led up to the prediction.

![markov](images/markov.png)

Markov chain analysis is a mathematical framework used to model and analyze systems that undergo transitions between different states over time. A Markov chain is a stochastic process where the future state depends only on the current state and not on the sequence of events that preceded it. In this case our "state" is the current word being observed. We will use the current state (word) to predict the next state (word).


```{r fig.align='center', fig.height=6, fig.width=6, message=FALSE, warning=FALSE, include=FALSE}
# Set our plot and code block specifications for the rest of the document.
knitr::opts_chunk$set(fig.width = 9,
                      fig.height = 6,
                      fig.align = "center",
                      # Set our code specifications for the rest of the document
                      echo = F,
                      warning = F,
                      message = F,
                      engine.path = list(python = '/Users/justinschulberg/.virtualenvs/blog_v/bin/python')
                      ) 

# Turn off scientific notation
options(scipen=999)

# Load in the Python path
# Sys.setenv(RETICULATE_PYTHON = "/Users/justinschulberg/opt/anaconda3/bin/python3")

# install.packages("pacman")
# Use pacman to load packages. This'll check to see if a package is already installed; if not, it'll install it. If it is installed, it'll run the library() function.
library(pacman)
pacman::p_load(
  readxl, # Used for reading in Excel packages
  tidyverse, # Used for easy data manipulation
  here, # Used for navigating project structures
  kableExtra, # Used for RMarkdown formatting
  DataExplorer, # Used for easy EDA
  corrplot, # Used for correlation plotting
  forcats, # Used for ordering ggplot variables
  ggplot2, # Used for plotting
  gridExtra, # Used for side-by-side plotting
  reticulate, # Used for Python programming
  pander # Pretty printing
  )


# Set our ggplot formats so we don't have to re-type the same code over-and-over again.
theme_set(theme_classic())
theme_update(plot.title = element_text(hjust = 0, color = "slateblue4", size = 20),
  plot.subtitle = element_text(hjust = 0, color = "slateblue2", size = 12),
  plot.caption = element_text(color = "dark gray", size = 10, face = "italic"),
  axis.title.x = element_text(size = 14),
  axis.title.y = element_text(size = 14),
  axis.text.y = element_text(size = 10),
  axis.text.x = element_text(size = 10))

# reticulate::use_python('/Users/justinschulberg/opt/anaconda3/bin/python3', require = TRUE)
# reticulate::use_condaenv(condaenv = 'bayes')

```


```{python}
# reticulate::use_virtualenv('blog_v')
import pandas as pd
import os

text = '''
I am so excited to graduate from Georgia Tech! 
I have loved my time studying at Georgia Tech and cannot wait to graduate.
'''

print(text)


```

## Word Bi-gram Co-occurrence Matrix
To start, I'll tokenize the text into words and split it into bigrams. Using the bigrams, I'll create a co-occurence matrix, $P_{ij}$ where $i$ represents the $i^{\text{th}}$ word and $j$ represents the $j^{\text{th}}$ word. The value of $P_{ij}$ then is the probability that word $j$ occurs immediately after word $i$.

```{python}

import nltk
import string
import pandas as pd
from sklearn.preprocessing import normalize
from tqdm import tqdm
from IPython.display import display, Math, Latex
from nltk.corpus import stopwords
import numpy as np

stop_words = stopwords.words('english')

def create_markov_matrix(text, order = 1):
    # Get a list of the tokenized words without punctuation
    tokens = [word.lower() for word in nltk.word_tokenize(text) if word not in string.punctuation]
    unique_tokens = list(dict.fromkeys(tokens))
    # print(unique_tokens)

    bigrams = list(nltk.bigrams(tokens))
    # print(bigrams)

    # Create a DataFrame where the rows are words and the columns are words
    df = pd.DataFrame(0, columns=unique_tokens, index=unique_tokens)

    # Loop through each of the bigrams (tuples), locate them in the DF, and add 1
    for i in bigrams:
        df.loc[i[0],i[1]] += 1

    # Convert the DataFrame from raw word counts to probabilities
    w_normalized = normalize(df, norm='l1', axis=1)

    if order > 1:
        w_normalized = np.linalg.matrix_power(w_normalized, order)
        
    df_normalized = pd.DataFrame(w_normalized, columns=unique_tokens, index=unique_tokens)

    return df_normalized

df_normalized = create_markov_matrix(text, order = 1)

display(df_normalized)
```

In the Markov transition matrix above we can see how, in the first row, given the word `I` (our current state), there are two words that could appear (our next state):

$$
P(\text{am } | \text{ I}) = .5 \\
P(\text{have } | \text{ I}) = .5
$$

It's important to note that these probabilities will **always** add up to 1; an important property of a [*row stochastic*](https://acme.byu.edu/00000179-af25-d5e1-a97b-bf6512fd0000/markov2020-pdf#:~:text=Thus%2C%20each%20of%20the%20columns,transition%20matrix%20sum%20to%201.&text=A%20transition%20matrix%20where%20the,stochastic%20(or%20left%20stochastic).) Markov chain.